{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1d1050-bc81-4ebb-8d19-aa98b98a19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas for loading datasets\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b60c675-bf03-49a2-8301-392c50a2f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv(\"AB_NYC_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95eaf430-f7b3-497d-90cc-219f777a5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Integrity: Ensuring the accuracy, consistency, and reliability of data throughout the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc48c05-fabc-4855-bab5-41ccace98cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after cleaning:\n",
      " id                                  int64\n",
      "name                               object\n",
      "host_id                             int64\n",
      "host_name                          object\n",
      "neighbourhood_group                object\n",
      "neighbourhood                      object\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "room_type                          object\n",
      "price                               int64\n",
      "minimum_nights                      int64\n",
      "number_of_reviews                   int64\n",
      "last_review                        object\n",
      "reviews_per_month                 float64\n",
      "calculated_host_listings_count      int64\n",
      "availability_365                    int64\n",
      "dtype: object\n",
      "\n",
      "Remaining missing values:\n",
      " id                                    0\n",
      "name                                 16\n",
      "host_id                               0\n",
      "host_name                            21\n",
      "neighbourhood_group                   0\n",
      "neighbourhood                         0\n",
      "latitude                              0\n",
      "longitude                             0\n",
      "room_type                             0\n",
      "price                                 0\n",
      "minimum_nights                        0\n",
      "number_of_reviews                     0\n",
      "last_review                       10051\n",
      "reviews_per_month                 10051\n",
      "calculated_host_listings_count        0\n",
      "availability_365                      0\n",
      "dtype: int64\n",
      "\n",
      "Clean dataset shape: (48884, 16)\n"
     ]
    }
   ],
   "source": [
    "# 1. Ensure correct data types\n",
    "\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df['minimum_nights'] = pd.to_numeric(df['minimum_nights'], errors='coerce')\n",
    "df['number_of_reviews'] = pd.to_numeric(df['number_of_reviews'], errors='coerce')\n",
    "\n",
    "# 2. Handleing invalid or inconsistent values\n",
    "# (Price must be positive)\n",
    "df = df[df['price'] > 0]\n",
    "\n",
    "# Minimum nights must be at least 1\n",
    "df = df[df['minimum_nights'] >= 1]\n",
    "\n",
    "# 3. Check value ranges and constraints\n",
    "# Latitude and longitude must be within valid ranges\n",
    "df = df[(df['latitude'].between(-90, 90)) & \n",
    "        (df['longitude'].between(-180, 180))]\n",
    "\n",
    "# 4. Removeing corrupted or incomplete records\n",
    "# Drop rows missing critical identifiers\n",
    "df = df.dropna(subset=['id', 'host_id'])\n",
    "\n",
    "# 5. Final integrity check\n",
    "\n",
    "print(\"Data types after cleaning:\\n\", df.dtypes)\n",
    "print(\"\\nRemaining missing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nClean dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc3aee8-99e7-4ca3-be62-6409e2e615dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Missing Data Handling: Dealing with missing values by either imputing them or making \n",
    "#informed decisions on how to handle gaps in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf832f22-ee46-432b-9d3e-5df7e166df54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "id                                    0\n",
      "name                                 16\n",
      "host_id                               0\n",
      "host_name                            21\n",
      "neighbourhood_group                   0\n",
      "neighbourhood                         0\n",
      "latitude                              0\n",
      "longitude                             0\n",
      "room_type                             0\n",
      "price                                 0\n",
      "minimum_nights                        0\n",
      "number_of_reviews                     0\n",
      "last_review                       10051\n",
      "reviews_per_month                 10051\n",
      "calculated_host_listings_count        0\n",
      "availability_365                      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after handling:\n",
      "id                                    0\n",
      "name                                 16\n",
      "host_id                               0\n",
      "host_name                            21\n",
      "neighbourhood_group                   0\n",
      "neighbourhood                         0\n",
      "latitude                              0\n",
      "longitude                             0\n",
      "room_type                             0\n",
      "price                                 0\n",
      "minimum_nights                        0\n",
      "number_of_reviews                     0\n",
      "last_review                       10051\n",
      "reviews_per_month                     0\n",
      "calculated_host_listings_count        0\n",
      "availability_365                      0\n",
      "dtype: int64\n",
      "\n",
      "Clean dataset shape: (48884, 16)\n"
     ]
    }
   ],
   "source": [
    "# 1. Identifying missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Impute missing values\n",
    "# Useing median for numerical column (robust to outliers)\n",
    "df['reviews_per_month'] = df['reviews_per_month'].fillna(\n",
    "    df['reviews_per_month'].median()\n",
    ")\n",
    "\n",
    "# Useing mode for categorical column\n",
    "df['neighbourhood_group'] = df['neighbourhood_group'].fillna(\n",
    "    df['neighbourhood_group'].mode()[0]\n",
    ")\n",
    "\n",
    "# 3. Informed removal of records\n",
    "# Drop rows where critical information is missing\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# 4. Final check\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nClean dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d728c855-4d62-49a8-86cc-e14b388ac50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Duplicate Removal: Identifying and eliminating duplicate records to maintain data uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a55c0ea-bc74-471e-a845-919883c7bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows: 0\n",
      "Duplicate IDs found: 0\n",
      "\n",
      "Dataset shape after duplicate removal: (48884, 16)\n",
      "Remaining duplicate IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check total duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(\"Total duplicate rows:\", duplicate_count)\n",
    "\n",
    "# Identifying duplicates based on key columns\n",
    "key_duplicates = df.duplicated(subset=['id'], keep=False)\n",
    "print(\"Duplicate IDs found:\", key_duplicates.sum())\n",
    "\n",
    "# Removeing duplicate records\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Removeing duplicates based on unique identifier (keep first occurrence)\n",
    "df = df.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "# Final validation\n",
    "print(\"\\nDataset shape after duplicate removal:\", df.shape)\n",
    "print(\"Remaining duplicate IDs:\", df['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "838d94d6-b0d7-4448-a0b6-f61f396f1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardization: Consistent formatting and units across the dataset for accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ddc3857-93d3-478f-aef9-d0db99bf0006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data types:\n",
      "\n",
      "id                                         int64\n",
      "name                                      object\n",
      "host_id                                    int64\n",
      "host_name                                 object\n",
      "neighbourhood_group                       object\n",
      "neighbourhood                             object\n",
      "latitude                                 float64\n",
      "longitude                                float64\n",
      "room_type                                 object\n",
      "price                                      int64\n",
      "minimum_nights                             int64\n",
      "number_of_reviews                          int64\n",
      "last_review                       datetime64[ns]\n",
      "reviews_per_month                        float64\n",
      "calculated_host_listings_count             int64\n",
      "availability_365                           int64\n",
      "dtype: object\n",
      "\n",
      "Sample standardized data:\n",
      "  neighbourhood_group        room_type  price last_review\n",
      "0            Brooklyn     private room    149  2018-10-19\n",
      "1           Manhattan  entire home/apt    225  2019-05-21\n",
      "2           Manhattan     private room    150         NaT\n",
      "3            Brooklyn  entire home/apt     89  2019-07-05\n",
      "4           Manhattan  entire home/apt     80  2018-11-19\n"
     ]
    }
   ],
   "source": [
    "# 1. Standardizeing text formatting\n",
    "df['neighbourhood_group'] = (\n",
    "    df['neighbourhood_group']\n",
    "    .str.strip()        # remove extra spaces\n",
    "    .str.title()        # consistent capitalization\n",
    ")\n",
    "\n",
    "df['room_type'] = (\n",
    "    df['room_type']\n",
    "    .str.strip()\n",
    "    .str.lower()        # consistent lowercase\n",
    ")\n",
    "\n",
    "# 2. Standardizeing date formats\n",
    "df['last_review'] = pd.to_datetime(\n",
    "    df['last_review'], errors='coerce'\n",
    ")\n",
    "\n",
    "# 3. Standardizeing numerical units\n",
    "# Ensure price is numeric and rounded to two decimals\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce').round(2)\n",
    "\n",
    "# Ensure availability is integer (days)\n",
    "df['availability_365'] = df['availability_365'].astype(int)\n",
    "\n",
    "# 4. Final validation\n",
    "print(\"Standardized data types:\\n\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nSample standardized data:\")\n",
    "print(df[['neighbourhood_group', 'room_type', 'price', 'last_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b2d87f-b9be-40b1-b416-07fc6b42fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Outlier Detection: Identifying and addressing outliers that may skew analysis or model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b5c37ee-2d2d-40fb-b0ab-11c049ffd147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of price outliers: 2972\n",
      "Dataset shape after removing outliers: (45912, 16)\n"
     ]
    }
   ],
   "source": [
    "# 1. Detecting outliers using IQR\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identifying outliers\n",
    "outliers = df[(df['price'] < lower_bound) | (df['price'] > upper_bound)]\n",
    "print(\"Number of price outliers:\", outliers.shape[0])\n",
    "\n",
    "# 2. Address outliers\n",
    "# Option 1: Remove outliers\n",
    "df_no_outliers = df[\n",
    "    (df['price'] >= lower_bound) & (df['price'] <= upper_bound)\n",
    "]\n",
    "\n",
    "# Option 2: Cap outliers (winsorization)\n",
    "df['price_capped'] = df['price'].clip(\n",
    "    lower=lower_bound,\n",
    "    upper=upper_bound\n",
    ")\n",
    "\n",
    "# 3. Final check\n",
    "print(\"Dataset shape after removing outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68082599-0cd7-45d6-b49b-653f564c8736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722a556-8f11-456c-a74c-aee9b01f16d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc03d89-6884-480c-af37-8177075dccb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4837767-85e2-4d12-ab66-1f47ef13b954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab04ae2-8c09-4f56-88cc-b54b2c59fe54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e66bb4-fcb9-4a61-8199-a6ddc9a88e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fbe5e-5fb6-4622-a583-75e575b4623e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8b1608-6966-4e99-b879-2cf5cb631c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    kind                                               etag  \\\n",
      "0  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/Xy1mB4_yLrHy_BmKm...   \n",
      "1  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/UZ1oLIIz2dxIhO45Z...   \n",
      "2  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/nqRIq97-xe5XRZTxb...   \n",
      "3  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/HwXKamM1Q20q9BN-o...   \n",
      "4  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/9GQMSRjrZdHeb1OEM...   \n",
      "\n",
      "   id         snippet.channelId     snippet.title  snippet.assignable  \n",
      "0   1  UCBR8-60-B28hp2BmDPdntcQ  Film & Animation                True  \n",
      "1   2  UCBR8-60-B28hp2BmDPdntcQ  Autos & Vehicles                True  \n",
      "2  10  UCBR8-60-B28hp2BmDPdntcQ             Music                True  \n",
      "3  15  UCBR8-60-B28hp2BmDPdntcQ    Pets & Animals                True  \n",
      "4  17  UCBR8-60-B28hp2BmDPdntcQ            Sports                True  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"CA_category_id.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.json_normalize(data['items'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e471224-2c56-4035-9c8e-aba41f84feac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind                  object\n",
      "etag                  object\n",
      "id                     int64\n",
      "snippet.channelId     object\n",
      "snippet.title         object\n",
      "snippet.assignable      bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct data types\n",
    "df['id'] = df['id'].astype(int)\n",
    "df['snippet.assignable'] = df['snippet.assignable'].astype(bool)\n",
    "\n",
    "# Remove records with missing critical fields\n",
    "df = df.dropna(subset=['id', 'snippet.title'])\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "168cf730-408a-40d6-a0a3-40b2865d3a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind                  0\n",
      "etag                  0\n",
      "id                    0\n",
      "snippet.channelId     0\n",
      "snippet.title         0\n",
      "snippet.assignable    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing channel IDs with 'Unknown'\n",
    "df['snippet.channelId'] = df['snippet.channelId'].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a13cff86-0b15-4e3f-a9ea-88f65094690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check duplicates based on category ID\n",
    "print(\"Duplicate IDs:\", df['id'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bcf30a7-3344-4b21-839a-75fba9836d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize text formatting\n",
    "df['snippet.title'] = (\n",
    "    df['snippet.title']\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "df = df.rename(columns={\n",
    "    'snippet.title': 'category_name',\n",
    "    'snippet.assignable': 'assignable'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ec98011-8651-4b7d-b003-4a616b821807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid IDs found: 0\n",
      "assignable\n",
      "False    17\n",
      "True     14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check invalid IDs (should be positive)\n",
    "invalid_ids = df[df['id'] <= 0]\n",
    "print(\"Invalid IDs found:\", invalid_ids.shape[0])\n",
    "\n",
    "# Check unexpected boolean values\n",
    "print(df['assignable'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7d9d3c3-f576-4897-98ed-e5b9f6047d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    kind                                               etag  \\\n",
      "0  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/Xy1mB4_yLrHy_BmKm...   \n",
      "1  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/UZ1oLIIz2dxIhO45Z...   \n",
      "2  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/nqRIq97-xe5XRZTxb...   \n",
      "3  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/HwXKamM1Q20q9BN-o...   \n",
      "4  youtube#videoCategory  \"ld9biNPKjAjgjV7EZ4EKeEGrhao/9GQMSRjrZdHeb1OEM...   \n",
      "\n",
      "   id         snippet.channelId     category_name  assignable  \n",
      "0   1  UCBR8-60-B28hp2BmDPdntcQ  Film & Animation        True  \n",
      "1   2  UCBR8-60-B28hp2BmDPdntcQ  Autos & Vehicles        True  \n",
      "2  10  UCBR8-60-B28hp2BmDPdntcQ             Music        True  \n",
      "3  15  UCBR8-60-B28hp2BmDPdntcQ    Pets & Animals        True  \n",
      "4  17  UCBR8-60-B28hp2BmDPdntcQ            Sports        True  \n",
      "Final dataset shape: (31, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(\"Final dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f2371-1f3e-498b-be31-823102b205db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
